{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf9747f",
   "metadata": {},
   "source": [
    "# üöÄ Kenya Clinical Reasoning - PRODUCTION ML TRAINING\n",
    "**FLAN-T5-small Fine-tuning on Expert Clinical Data**\n",
    "\n",
    "**Target:** Competition-winning model using REAL expert responses  \n",
    "**Hardware:** Kaggle P100 GPU acceleration  \n",
    "**Model:** Google FLAN-T5-small (77M params, edge-deployable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install transformers torch rouge-score datasets accelerate -q\n",
    "\n",
    "# Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our existing modules\n",
    "sys.path.append('.')\n",
    "from core.ml_model import MLPipeline, ClinicalT5Model, ClinicalExample\n",
    "from utils.logger import CompetitionLogger\n",
    "\n",
    "# Initialize\n",
    "logger = CompetitionLogger(\"ML_Training\")\n",
    "logger.info(\"üöÄ PRODUCTION ML TRAINING STARTED\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "print(f\"üìä Loaded {len(train_df)} training cases\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "\n",
    "# Check expert response columns\n",
    "expert_cols = ['Nursing Competency', 'Clinical Panel', 'Clinician', 'GPT4.0', 'LLAMA', 'GEMINI']\n",
    "for col in expert_cols:\n",
    "    if col in train_df.columns:\n",
    "        filled = train_df[col].notna().sum()\n",
    "        print(f\"‚úÖ {col}: {filled}/{len(train_df)} responses ({filled/len(train_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FLAN-T5 model\n",
    "model = ClinicalT5Model(\"google/flan-t5-small\")\n",
    "logger.info(f\"Model loaded: {sum(p.numel() for p in model.model.parameters()):,} parameters\")\n",
    "\n",
    "# Prepare training examples from REAL expert data\n",
    "training_examples = model.prepare_training_data(train_df)\n",
    "logger.info(f\"‚úÖ Prepared {len(training_examples)} training examples\")\n",
    "\n",
    "# Show sample\n",
    "if training_examples:\n",
    "    sample = training_examples[0]\n",
    "    print(\"üìã SAMPLE TRAINING EXAMPLE:\")\n",
    "    print(f\"Input: {sample.input_text[:200]}...\")\n",
    "    print(f\"Target: {sample.target_response[:200]}...\")\n",
    "    print(f\"Length: {len(sample.target_response)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664501d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data\n",
    "train_size = int(0.85 * len(training_examples))\n",
    "train_examples = training_examples[:train_size]\n",
    "val_examples = training_examples[train_size:]\n",
    "\n",
    "logger.info(f\"üìà Training: {len(train_examples)}, Validation: {len(val_examples)}\")\n",
    "\n",
    "# Training configuration for GPU acceleration\n",
    "config = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 8,  # Increase for P100\n",
    "    'learning_rate': 3e-5,\n",
    "}\n",
    "\n",
    "logger.info(f\"üîß Training config: {config}\")\n",
    "\n",
    "# Start training (this will take several minutes on P100)\n",
    "print(\"üöÄ STARTING FINE-TUNING...\")\n",
    "training_results = model.fine_tune(\n",
    "    train_examples=train_examples,\n",
    "    val_examples=val_examples,\n",
    "    **config\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Training completed!\")\n",
    "print(\"üìä Training Results:\")\n",
    "for stat in training_results['training_stats']:\n",
    "    print(f\"Epoch {stat['epoch']}: Loss={stat['train_loss']:.4f}, ROUGE-L={stat.get('rouge_l', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and generate predictions\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "logger.info(f\"üìã Generating predictions for {len(test_df)} test cases...\")\n",
    "\n",
    "predictions = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    # Create input prompt\n",
    "    input_prompt = model._create_input_prompt(row)\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.generate_response(input_prompt, max_length=200)\n",
    "    predictions.append(response)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Generated {idx+1}/{len(test_df)} predictions\")\n",
    "\n",
    "logger.info(\"‚úÖ All predictions generated!\")\n",
    "\n",
    "# Analyze prediction lengths\n",
    "lengths = [len(p) for p in predictions]\n",
    "print(f\"üìè Prediction lengths: Mean={np.mean(lengths):.1f}, Range={min(lengths)}-{max(lengths)}\")\n",
    "target_range = [(l >= 600 and l <= 800) for l in lengths]\n",
    "print(f\"üéØ Target range (600-800 chars): {sum(target_range)}/{len(target_range)} ({np.mean(target_range)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': range(len(predictions)),\n",
    "    'response': predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = 'flan_t5_submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "logger.info(f\"üíæ Submission saved: {submission_path}\")\n",
    "\n",
    "# Save model\n",
    "model_path = 'flan_t5_clinical_model'\n",
    "model.save_model(model_path)\n",
    "logger.info(f\"ü§ñ Model saved: {model_path}\")\n",
    "\n",
    "# Create final summary\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'FLAN-T5-small',\n",
    "    'parameters': sum(p.numel() for p in model.model.parameters()),\n",
    "    'training_examples': len(train_examples),\n",
    "    'validation_examples': len(val_examples),\n",
    "    'test_predictions': len(predictions),\n",
    "    'mean_response_length': float(np.mean(lengths)),\n",
    "    'target_range_percentage': float(np.mean(target_range) * 100),\n",
    "    'training_results': training_results,\n",
    "    'submission_file': submission_path,\n",
    "    'model_path': model_path\n",
    "}\n",
    "\n",
    "with open('training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"üèÜ PRODUCTION ML TRAINING COMPLETE!\")\n",
    "print(f\"‚úÖ Model: {summary['parameters']:,} parameters\")\n",
    "print(f\"‚úÖ Submission: {submission_path}\")\n",
    "print(f\"‚úÖ Mean length: {summary['mean_response_length']:.1f} chars\")\n",
    "print(f\"‚úÖ Target range: {summary['target_range_percentage']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7023f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"üîç SAMPLE PREDICTIONS:\")\n",
    "for i in range(min(3, len(predictions))):\n",
    "    print(f\"\\n--- CASE {i+1} ---\")\n",
    "    print(f\"Length: {len(predictions[i])} chars\")\n",
    "    print(f\"Response: {predictions[i]}\")\n",
    "\n",
    "# Quantize model for edge deployment (optional)\n",
    "print(\"\\nüîß Quantizing model for edge deployment...\")\n",
    "quantized_model = model.quantize_for_edge()\n",
    "print(\"‚úÖ Quantized model ready for Jetson Nano deployment\")\n",
    "\n",
    "# Final download instructions\n",
    "print(\"\\nüì• DOWNLOAD FILES:\")\n",
    "print(\"1. flan_t5_submission.csv - Competition submission\")\n",
    "print(\"2. flan_t5_clinical_model/ - Trained model directory\") \n",
    "print(\"3. training_summary.json - Training metrics\")\n",
    "\n",
    "logger.info(\"üéØ READY FOR COMPETITION SUBMISSION!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b82bf8",
   "metadata": {},
   "source": [
    "# üè• Kenya Clinical Reasoning Challenge - Production ML Training\n",
    "\n",
    "**REAL ML MODEL TRAINING ON KAGGLE P100 GPU**\n",
    "\n",
    "This notebook implements a production-grade FLAN-T5-small model fine-tuned on REAL expert clinical responses for the Kenya Clinical Reasoning Challenge competition.\n",
    "\n",
    "## üéØ Competition Goals\n",
    "- **Model Size:** <1B parameters (FLAN-T5-small = 77M ‚úÖ)\n",
    "- **Training Data:** Expert clinical responses from Kenyan healthcare professionals\n",
    "- **Target Length:** ~700 characters per response\n",
    "- **Evaluation:** ROUGE metrics for response quality\n",
    "- **Deployment:** Edge-compatible (Jetson Nano ready)\n",
    "\n",
    "## üöÄ Key Features\n",
    "- GPU-accelerated training on Kaggle P100\n",
    "- Real expert response fine-tuning (no templates!)\n",
    "- ROUGE-based evaluation and optimization\n",
    "- Automatic submission generation\n",
    "- Clean project structure with separation of concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce684f",
   "metadata": {},
   "source": [
    "## 1. üî• Set Up Kaggle GPU Environment\n",
    "\n",
    "First, let's verify we have GPU access and check if it's the P100 variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b66e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"üîç GPU Environment Check:\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Check GPU memory\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Verify it's P100 (should have ~16GB memory)\n",
    "    if \"P100\" in torch.cuda.get_device_name(0) or gpu_memory > 15:\n",
    "        print(\"‚úÖ P100 GPU Detected - Ready for training!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Different GPU detected - will still work but may be slower\")\n",
    "else:\n",
    "    print(\"‚ùå No GPU detected - will run on CPU (much slower)\")\n",
    "\n",
    "# Check system info\n",
    "print(f\"\\nüíª System Info:\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0c099",
   "metadata": {},
   "source": [
    "## 2. üì¶ Install and Import Required Libraries\n",
    "\n",
    "Install all necessary ML dependencies for transformer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be490116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install transformers datasets rouge-score accelerate -q\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ML imports\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset as HFDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bd458",
   "metadata": {},
   "source": [
    "## 3. üìÅ Configure Project Directory Structure\n",
    "\n",
    "Set up clean separation of concerns with core/, utils/, logs/ directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff46719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up project structure\n",
    "PROJECT_ROOT = Path(\"/kaggle/working\")\n",
    "DATA_DIR = Path(\"/kaggle/input\")  # Kaggle input data location\n",
    "\n",
    "# Create required directories\n",
    "directories = {\n",
    "    'core': PROJECT_ROOT / 'core',\n",
    "    'utils': PROJECT_ROOT / 'utils', \n",
    "    'logs': PROJECT_ROOT / 'logs',\n",
    "    'models': PROJECT_ROOT / 'models',\n",
    "    'results': PROJECT_ROOT / 'results',\n",
    "    'configs': PROJECT_ROOT / 'configs'\n",
    "}\n",
    "\n",
    "for name, path in directories.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created {name}/ directory\")\n",
    "\n",
    "# Set up paths\n",
    "PATHS = {\n",
    "    'project_root': PROJECT_ROOT,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'train_data': DATA_DIR / 'train.csv',  # Update with actual Kaggle dataset path\n",
    "    'test_data': DATA_DIR / 'test.csv',\n",
    "    'logs': directories['logs'],\n",
    "    'models': directories['models'],\n",
    "    'results': directories['results']\n",
    "}\n",
    "\n",
    "print(f\"\\nüìÅ Project structure ready at: {PROJECT_ROOT}\")\n",
    "print(f\"üìä Data expected at: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916231e9",
   "metadata": {},
   "source": [
    "## 4. ‚öôÔ∏è Load Configuration and Set Up Logging\n",
    "\n",
    "Configure training parameters and initialize logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (optimized for P100)\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'name': 'google/flan-t5-small',  # 77M parameters\n",
    "        'max_length': 512,\n",
    "        'target_length': 200\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 8,  # Optimized for P100 16GB\n",
    "        'learning_rate': 5e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_ratio': 0.1,\n",
    "        'weight_decay': 0.01,\n",
    "        'gradient_accumulation_steps': 2\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'eval_steps': 100,\n",
    "        'save_steps': 500,\n",
    "        'logging_steps': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simple logging setup\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Save config\n",
    "config_path = PATHS['project_root'] / 'configs' / 'training_config.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(CONFIG, f, default_flow_style=False)\n",
    "\n",
    "logger.info(f\"‚úÖ Configuration loaded and saved to {config_path}\")\n",
    "print(f\"üîß Training Config: {CONFIG['model']['name']} on {device}\")\n",
    "print(f\"üìä Batch size: {CONFIG['training']['batch_size']}, Epochs: {CONFIG['training']['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec06ce",
   "metadata": {},
   "source": [
    "## 5. üìä Prepare Dataset with REAL Expert Responses\n",
    "\n",
    "Load and preprocess the training data using actual expert clinical responses."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
