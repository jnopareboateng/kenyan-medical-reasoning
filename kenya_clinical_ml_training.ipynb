{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf9747f",
   "metadata": {},
   "source": [
    "# 🚀 Kenya Clinical Reasoning - PRODUCTION ML TRAINING\n",
    "**FLAN-T5-small Fine-tuning on Expert Clinical Data**\n",
    "\n",
    "**Target:** Competition-winning model using REAL expert responses  \n",
    "**Hardware:** Kaggle P100 GPU acceleration  \n",
    "**Model:** Google FLAN-T5-small (77M params, edge-deployable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install transformers torch rouge-score datasets accelerate -q\n",
    "\n",
    "# Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🔥 Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our existing modules\n",
    "sys.path.append('.')\n",
    "from core.ml_model import MLPipeline, ClinicalT5Model, ClinicalExample\n",
    "from utils.logger import CompetitionLogger\n",
    "\n",
    "# Initialize\n",
    "logger = CompetitionLogger(\"ML_Training\")\n",
    "logger.info(\"🚀 PRODUCTION ML TRAINING STARTED\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "print(f\"📊 Loaded {len(train_df)} training cases\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "\n",
    "# Check expert response columns\n",
    "expert_cols = ['Nursing Competency', 'Clinical Panel', 'Clinician', 'GPT4.0', 'LLAMA', 'GEMINI']\n",
    "for col in expert_cols:\n",
    "    if col in train_df.columns:\n",
    "        filled = train_df[col].notna().sum()\n",
    "        print(f\"✅ {col}: {filled}/{len(train_df)} responses ({filled/len(train_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FLAN-T5 model\n",
    "model = ClinicalT5Model(\"google/flan-t5-small\")\n",
    "logger.info(f\"Model loaded: {sum(p.numel() for p in model.model.parameters()):,} parameters\")\n",
    "\n",
    "# Prepare training examples from REAL expert data\n",
    "training_examples = model.prepare_training_data(train_df)\n",
    "logger.info(f\"✅ Prepared {len(training_examples)} training examples\")\n",
    "\n",
    "# Show sample\n",
    "if training_examples:\n",
    "    sample = training_examples[0]\n",
    "    print(\"📋 SAMPLE TRAINING EXAMPLE:\")\n",
    "    print(f\"Input: {sample.input_text[:200]}...\")\n",
    "    print(f\"Target: {sample.target_response[:200]}...\")\n",
    "    print(f\"Length: {len(sample.target_response)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664501d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data\n",
    "train_size = int(0.85 * len(training_examples))\n",
    "train_examples = training_examples[:train_size]\n",
    "val_examples = training_examples[train_size:]\n",
    "\n",
    "logger.info(f\"📈 Training: {len(train_examples)}, Validation: {len(val_examples)}\")\n",
    "\n",
    "# Training configuration for GPU acceleration\n",
    "config = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 8,  # Increase for P100\n",
    "    'learning_rate': 3e-5,\n",
    "}\n",
    "\n",
    "logger.info(f\"🔧 Training config: {config}\")\n",
    "\n",
    "# Start training (this will take several minutes on P100)\n",
    "print(\"🚀 STARTING FINE-TUNING...\")\n",
    "training_results = model.fine_tune(\n",
    "    train_examples=train_examples,\n",
    "    val_examples=val_examples,\n",
    "    **config\n",
    ")\n",
    "\n",
    "logger.info(\"✅ Training completed!\")\n",
    "print(\"📊 Training Results:\")\n",
    "for stat in training_results['training_stats']:\n",
    "    print(f\"Epoch {stat['epoch']}: Loss={stat['train_loss']:.4f}, ROUGE-L={stat.get('rouge_l', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and generate predictions\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "logger.info(f\"📋 Generating predictions for {len(test_df)} test cases...\")\n",
    "\n",
    "predictions = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    # Create input prompt\n",
    "    input_prompt = model._create_input_prompt(row)\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.generate_response(input_prompt, max_length=200)\n",
    "    predictions.append(response)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Generated {idx+1}/{len(test_df)} predictions\")\n",
    "\n",
    "logger.info(\"✅ All predictions generated!\")\n",
    "\n",
    "# Analyze prediction lengths\n",
    "lengths = [len(p) for p in predictions]\n",
    "print(f\"📏 Prediction lengths: Mean={np.mean(lengths):.1f}, Range={min(lengths)}-{max(lengths)}\")\n",
    "target_range = [(l >= 600 and l <= 800) for l in lengths]\n",
    "print(f\"🎯 Target range (600-800 chars): {sum(target_range)}/{len(target_range)} ({np.mean(target_range)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': range(len(predictions)),\n",
    "    'response': predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = 'flan_t5_submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "logger.info(f\"💾 Submission saved: {submission_path}\")\n",
    "\n",
    "# Save model\n",
    "model_path = 'flan_t5_clinical_model'\n",
    "model.save_model(model_path)\n",
    "logger.info(f\"🤖 Model saved: {model_path}\")\n",
    "\n",
    "# Create final summary\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'FLAN-T5-small',\n",
    "    'parameters': sum(p.numel() for p in model.model.parameters()),\n",
    "    'training_examples': len(train_examples),\n",
    "    'validation_examples': len(val_examples),\n",
    "    'test_predictions': len(predictions),\n",
    "    'mean_response_length': float(np.mean(lengths)),\n",
    "    'target_range_percentage': float(np.mean(target_range) * 100),\n",
    "    'training_results': training_results,\n",
    "    'submission_file': submission_path,\n",
    "    'model_path': model_path\n",
    "}\n",
    "\n",
    "with open('training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"🏆 PRODUCTION ML TRAINING COMPLETE!\")\n",
    "print(f\"✅ Model: {summary['parameters']:,} parameters\")\n",
    "print(f\"✅ Submission: {submission_path}\")\n",
    "print(f\"✅ Mean length: {summary['mean_response_length']:.1f} chars\")\n",
    "print(f\"✅ Target range: {summary['target_range_percentage']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7023f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"🔍 SAMPLE PREDICTIONS:\")\n",
    "for i in range(min(3, len(predictions))):\n",
    "    print(f\"\\n--- CASE {i+1} ---\")\n",
    "    print(f\"Length: {len(predictions[i])} chars\")\n",
    "    print(f\"Response: {predictions[i]}\")\n",
    "\n",
    "# Quantize model for edge deployment (optional)\n",
    "print(\"\\n🔧 Quantizing model for edge deployment...\")\n",
    "quantized_model = model.quantize_for_edge()\n",
    "print(\"✅ Quantized model ready for Jetson Nano deployment\")\n",
    "\n",
    "# Final download instructions\n",
    "print(\"\\n📥 DOWNLOAD FILES:\")\n",
    "print(\"1. flan_t5_submission.csv - Competition submission\")\n",
    "print(\"2. flan_t5_clinical_model/ - Trained model directory\") \n",
    "print(\"3. training_summary.json - Training metrics\")\n",
    "\n",
    "logger.info(\"🎯 READY FOR COMPETITION SUBMISSION!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b82bf8",
   "metadata": {},
   "source": [
    "# 🏥 Kenya Clinical Reasoning Challenge - Production ML Training\n",
    "\n",
    "**REAL ML MODEL TRAINING ON KAGGLE P100 GPU**\n",
    "\n",
    "This notebook implements a production-grade FLAN-T5-small model fine-tuned on REAL expert clinical responses for the Kenya Clinical Reasoning Challenge competition.\n",
    "\n",
    "## 🎯 Competition Goals\n",
    "- **Model Size:** <1B parameters (FLAN-T5-small = 77M ✅)\n",
    "- **Training Data:** Expert clinical responses from Kenyan healthcare professionals\n",
    "- **Target Length:** ~700 characters per response\n",
    "- **Evaluation:** ROUGE metrics for response quality\n",
    "- **Deployment:** Edge-compatible (Jetson Nano ready)\n",
    "\n",
    "## 🚀 Key Features\n",
    "- GPU-accelerated training on Kaggle P100\n",
    "- Real expert response fine-tuning (no templates!)\n",
    "- ROUGE-based evaluation and optimization\n",
    "- Automatic submission generation\n",
    "- Clean project structure with separation of concerns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce684f",
   "metadata": {},
   "source": [
    "## 1. 🔥 Set Up Kaggle GPU Environment\n",
    "\n",
    "First, let's verify we have GPU access and check if it's the P100 variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b66e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import subprocess\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"🔍 GPU Environment Check:\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    \n",
    "    # Check GPU memory\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    # Verify it's P100 (should have ~16GB memory)\n",
    "    if \"P100\" in torch.cuda.get_device_name(0) or gpu_memory > 15:\n",
    "        print(\"✅ P100 GPU Detected - Ready for training!\")\n",
    "    else:\n",
    "        print(\"⚠️  Different GPU detected - will still work but may be slower\")\n",
    "else:\n",
    "    print(\"❌ No GPU detected - will run on CPU (much slower)\")\n",
    "\n",
    "# Check system info\n",
    "print(f\"\\n💻 System Info:\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Training Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf0c099",
   "metadata": {},
   "source": [
    "## 2. 📦 Install and Import Required Libraries\n",
    "\n",
    "Install all necessary ML dependencies for transformer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be490116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "!pip install transformers datasets rouge-score accelerate -q\n",
    "\n",
    "print(\"✅ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8282ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core ML imports\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset as HFDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bd458",
   "metadata": {},
   "source": [
    "## 3. 📁 Configure Project Directory Structure\n",
    "\n",
    "Set up clean separation of concerns with core/, utils/, logs/ directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff46719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up project structure\n",
    "PROJECT_ROOT = Path(\"/kaggle/working\")\n",
    "DATA_DIR = Path(\"/kaggle/input\")  # Kaggle input data location\n",
    "\n",
    "# Create required directories\n",
    "directories = {\n",
    "    'core': PROJECT_ROOT / 'core',\n",
    "    'utils': PROJECT_ROOT / 'utils', \n",
    "    'logs': PROJECT_ROOT / 'logs',\n",
    "    'models': PROJECT_ROOT / 'models',\n",
    "    'results': PROJECT_ROOT / 'results',\n",
    "    'configs': PROJECT_ROOT / 'configs'\n",
    "}\n",
    "\n",
    "for name, path in directories.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✅ Created {name}/ directory\")\n",
    "\n",
    "# Set up paths\n",
    "PATHS = {\n",
    "    'project_root': PROJECT_ROOT,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'train_data': DATA_DIR / 'train.csv',  # Update with actual Kaggle dataset path\n",
    "    'test_data': DATA_DIR / 'test.csv',\n",
    "    'logs': directories['logs'],\n",
    "    'models': directories['models'],\n",
    "    'results': directories['results']\n",
    "}\n",
    "\n",
    "print(f\"\\n📁 Project structure ready at: {PROJECT_ROOT}\")\n",
    "print(f\"📊 Data expected at: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916231e9",
   "metadata": {},
   "source": [
    "## 4. ⚙️ Load Configuration and Set Up Logging\n",
    "\n",
    "Configure training parameters and initialize logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (optimized for P100)\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'name': 'google/flan-t5-small',  # 77M parameters\n",
    "        'max_length': 512,\n",
    "        'target_length': 200\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 8,  # Optimized for P100 16GB\n",
    "        'learning_rate': 5e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_ratio': 0.1,\n",
    "        'weight_decay': 0.01,\n",
    "        'gradient_accumulation_steps': 2\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'eval_steps': 100,\n",
    "        'save_steps': 500,\n",
    "        'logging_steps': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simple logging setup\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Save config\n",
    "config_path = PATHS['project_root'] / 'configs' / 'training_config.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(CONFIG, f, default_flow_style=False)\n",
    "\n",
    "logger.info(f\"✅ Configuration loaded and saved to {config_path}\")\n",
    "print(f\"🔧 Training Config: {CONFIG['model']['name']} on {device}\")\n",
    "print(f\"📊 Batch size: {CONFIG['training']['batch_size']}, Epochs: {CONFIG['training']['epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec06ce",
   "metadata": {},
   "source": [
    "## 5. 📊 Prepare Dataset with REAL Expert Responses\n",
    "\n",
    "Load and preprocess the training data using actual expert clinical responses."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
