{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf9747f",
   "metadata": {},
   "source": [
    "# üöÄ Kenya Clinical Reasoning - PRODUCTION ML TRAINING\n",
    "**FLAN-T5-small Fine-tuning on Expert Clinical Data**\n",
    "\n",
    "**Target:** Competition-winning model using REAL expert responses  \n",
    "**Hardware:** Kaggle P100 GPU acceleration  \n",
    "**Model:** Google FLAN-T5-small (77M params, edge-deployable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4125a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: cuda\n",
      "GPU: Tesla P100-PCIE-16GB\n",
      "Memory: 17.1GB\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install rouge-score datasets accelerate transformers torch -q\n",
    "\n",
    "# Setup\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Check PyTorch and transformers compatibility\n",
    "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Test AdamW import (fixed in newer versions)\n",
    "try:\n",
    "    from torch.optim import AdamW\n",
    "    print(\"‚úÖ AdamW imported from torch.optim (recommended)\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from transformers import AdamW\n",
    "        print(\"‚ö†Ô∏è AdamW imported from transformers (deprecated)\")\n",
    "    except ImportError:\n",
    "        print(\"‚ùå AdamW not found - installing latest transformers\")\n",
    "        !pip install --upgrade transformers torch\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU available - training will be slower on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d6a2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kenyan-medical-reasoning'...\n",
      "remote: Enumerating objects: 77, done.\u001b[K\n",
      "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
      "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
      "remote: Total 77 (delta 9), reused 77 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (77/77), 2.63 MiB | 21.56 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jnopareboateng/kenyan-medical-reasoning.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3a0f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5baa5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.virtual_documents', 'kenyan-medical-reasoning']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11871a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/kenyan-medical-reasoning\n"
     ]
    }
   ],
   "source": [
    "%cd kenyan-medical-reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e7eb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 18:30:01.296078: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750098601.318735     142 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750098601.325706     142 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/1617523526.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import our existing modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClinicalT5Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClinicalExample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompetitionLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/kenyan-medical-reasoning/core/ml_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Ensure all dependencies are imported first\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import our existing modules\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from core.ml_model import MLPipeline, ClinicalT5Model, ClinicalExample\n",
    "from utils.logger import CompetitionLogger\n",
    "\n",
    "# Initialize\n",
    "logger = CompetitionLogger(\"ML_Training\")\n",
    "logger.info(\"üöÄ PRODUCTION ML TRAINING STARTED\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"üìä Loaded {len(train_df)} training cases\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")\n",
    "\n",
    "# Check expert response columns\n",
    "expert_cols = [\n",
    "    \"Nursing Competency\",\n",
    "    \"Clinical Panel\", \n",
    "    \"Clinician\",\n",
    "    \"GPT4.0\",\n",
    "    \"LLAMA\",\n",
    "    \"GEMINI\",\n",
    "]\n",
    "for col in expert_cols:\n",
    "    if col in train_df.columns:\n",
    "        filled = train_df[col].notna().sum()\n",
    "        print(\n",
    "            f\"‚úÖ {col}: {filled}/{len(train_df)} responses ({filled/len(train_df)*100:.1f}%)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick import test to verify everything works\n",
    "print(\"üîç Testing imports...\")\n",
    "\n",
    "try:\n",
    "    from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "    from torch.optim import AdamW\n",
    "    print(\"‚úÖ Transformers and PyTorch imports successful\")\n",
    "    \n",
    "    from core.ml_model import ClinicalT5Model\n",
    "    print(\"‚úÖ Custom ML model import successful\")\n",
    "    \n",
    "    print(\"üéØ All imports working - ready for training!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Installing missing dependencies...\")\n",
    "    !pip install rouge-score datasets accelerate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdcf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FLAN-T5 model\n",
    "model = ClinicalT5Model(\"google/flan-t5-small\")\n",
    "logger.info(f\"Model loaded: {sum(p.numel() for p in model.model.parameters()):,} parameters\")\n",
    "\n",
    "# Prepare training examples from REAL expert data\n",
    "training_examples = model.prepare_training_data(train_df)\n",
    "logger.info(f\"‚úÖ Prepared {len(training_examples)} training examples\")\n",
    "\n",
    "# Show sample\n",
    "if training_examples:\n",
    "    sample = training_examples[0]\n",
    "    print(\"üìã SAMPLE TRAINING EXAMPLE:\")\n",
    "    print(f\"Input: {sample.input_text[:200]}...\")\n",
    "    print(f\"Target: {sample.target_response[:200]}...\")\n",
    "    print(f\"Length: {len(sample.target_response)} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664501d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data\n",
    "train_size = int(0.85 * len(training_examples))\n",
    "train_examples = training_examples[:train_size]\n",
    "val_examples = training_examples[train_size:]\n",
    "\n",
    "logger.info(f\"üìà Training: {len(train_examples)}, Validation: {len(val_examples)}\")\n",
    "\n",
    "# Training configuration for GPU acceleration\n",
    "config = {\n",
    "    'epochs': 3,\n",
    "    'batch_size': 8,  # Increase for P100\n",
    "    'learning_rate': 3e-5,\n",
    "}\n",
    "\n",
    "logger.info(f\"üîß Training config: {config}\")\n",
    "\n",
    "# Start training (this will take several minutes on P100)\n",
    "print(\"üöÄ STARTING FINE-TUNING...\")\n",
    "training_results = model.fine_tune(\n",
    "    train_examples=train_examples,\n",
    "    val_examples=val_examples,\n",
    "    **config\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Training completed!\")\n",
    "print(\"üìä Training Results:\")\n",
    "for stat in training_results['training_stats']:\n",
    "    print(f\"Epoch {stat['epoch']}: Loss={stat['train_loss']:.4f}, ROUGE-L={stat.get('rouge_l', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade52e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data and generate predictions\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "logger.info(f\"üìã Generating predictions for {len(test_df)} test cases...\")\n",
    "\n",
    "predictions = []\n",
    "for idx, row in test_df.iterrows():\n",
    "    # Create input prompt\n",
    "    input_prompt = model._create_input_prompt(row)\n",
    "    \n",
    "    # Generate response\n",
    "    response = model.generate_response(input_prompt, max_length=200)\n",
    "    predictions.append(response)\n",
    "    \n",
    "    if idx % 10 == 0:\n",
    "        print(f\"Generated {idx+1}/{len(test_df)} predictions\")\n",
    "\n",
    "logger.info(\"‚úÖ All predictions generated!\")\n",
    "\n",
    "# Analyze prediction lengths\n",
    "lengths = [len(p) for p in predictions]\n",
    "print(f\"üìè Prediction lengths: Mean={np.mean(lengths):.1f}, Range={min(lengths)}-{max(lengths)}\")\n",
    "target_range = [(l >= 600 and l <= 800) for l in lengths]\n",
    "print(f\"üéØ Target range (600-800 chars): {sum(target_range)}/{len(target_range)} ({np.mean(target_range)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2abbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': range(len(predictions)),\n",
    "    'response': predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission_path = 'flan_t5_submission.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "logger.info(f\"üíæ Submission saved: {submission_path}\")\n",
    "\n",
    "# Save model\n",
    "model_path = 'flan_t5_clinical_model'\n",
    "model.save_model(model_path)\n",
    "logger.info(f\"ü§ñ Model saved: {model_path}\")\n",
    "\n",
    "# Create final summary\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model': 'FLAN-T5-small',\n",
    "    'parameters': sum(p.numel() for p in model.model.parameters()),\n",
    "    'training_examples': len(train_examples),\n",
    "    'validation_examples': len(val_examples),\n",
    "    'test_predictions': len(predictions),\n",
    "    'mean_response_length': float(np.mean(lengths)),\n",
    "    'target_range_percentage': float(np.mean(target_range) * 100),\n",
    "    'training_results': training_results,\n",
    "    'submission_file': submission_path,\n",
    "    'model_path': model_path\n",
    "}\n",
    "\n",
    "with open('training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"üèÜ PRODUCTION ML TRAINING COMPLETE!\")\n",
    "print(f\"‚úÖ Model: {summary['parameters']:,} parameters\")\n",
    "print(f\"‚úÖ Submission: {submission_path}\")\n",
    "print(f\"‚úÖ Mean length: {summary['mean_response_length']:.1f} chars\")\n",
    "print(f\"‚úÖ Target range: {summary['target_range_percentage']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7023f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"üîç SAMPLE PREDICTIONS:\")\n",
    "for i in range(min(3, len(predictions))):\n",
    "    print(f\"\\n--- CASE {i+1} ---\")\n",
    "    print(f\"Length: {len(predictions[i])} chars\")\n",
    "    print(f\"Response: {predictions[i]}\")\n",
    "\n",
    "# Quantize model for edge deployment (optional)\n",
    "print(\"\\nüîß Quantizing model for edge deployment...\")\n",
    "quantized_model = model.quantize_for_edge()\n",
    "print(\"‚úÖ Quantized model ready for Jetson Nano deployment\")\n",
    "\n",
    "# Final download instructions\n",
    "print(\"\\nüì• DOWNLOAD FILES:\")\n",
    "print(\"1. flan_t5_submission.csv - Competition submission\")\n",
    "print(\"2. flan_t5_clinical_model/ - Trained model directory\") \n",
    "print(\"3. training_summary.json - Training metrics\")\n",
    "\n",
    "logger.info(\"üéØ READY FOR COMPETITION SUBMISSION!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8282ce3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_142/2959396363.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Core ML imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mT5ForConditionalGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mT5Tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AdamW' from 'transformers' (/usr/local/lib/python3.11/dist-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Core ML imports\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import Dataset as HFDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "import json\n",
    "import yaml\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3bd458",
   "metadata": {},
   "source": [
    "## 3. üìÅ Configure Project Directory Structure\n",
    "\n",
    "Set up clean separation of concerns with core/, utils/, logs/ directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff46719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up project structure\n",
    "PROJECT_ROOT = Path(\"/kaggle/working\")\n",
    "DATA_DIR = Path(\"/kaggle/input\")  # Kaggle input data location\n",
    "\n",
    "# Create required directories\n",
    "directories = {\n",
    "    'core': PROJECT_ROOT / 'core',\n",
    "    'utils': PROJECT_ROOT / 'utils', \n",
    "    'logs': PROJECT_ROOT / 'logs',\n",
    "    'models': PROJECT_ROOT / 'models',\n",
    "    'results': PROJECT_ROOT / 'results',\n",
    "    'configs': PROJECT_ROOT / 'configs'\n",
    "}\n",
    "\n",
    "for name, path in directories.items():\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"‚úÖ Created {name}/ directory\")\n",
    "\n",
    "# Set up paths\n",
    "PATHS = {\n",
    "    'project_root': PROJECT_ROOT,\n",
    "    'data_dir': DATA_DIR,\n",
    "    'train_data': DATA_DIR / 'train.csv',  # Update with actual Kaggle dataset path\n",
    "    'test_data': DATA_DIR / 'test.csv',\n",
    "    'logs': directories['logs'],\n",
    "    'models': directories['models'],\n",
    "    'results': directories['results']\n",
    "}\n",
    "\n",
    "print(f\"\\nüìÅ Project structure ready at: {PROJECT_ROOT}\")\n",
    "print(f\"üìä Data expected at: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916231e9",
   "metadata": {},
   "source": [
    "## 4. ‚öôÔ∏è Load Configuration and Set Up Logging\n",
    "\n",
    "Configure training parameters and initialize logging system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b01fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration (optimized for P100)\n",
    "CONFIG = {\n",
    "    'model': {\n",
    "        'name': 'google/flan-t5-small',  # 77M parameters\n",
    "        'max_length': 512,\n",
    "        'target_length': 200\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 8,  # Optimized for P100 16GB\n",
    "        'learning_rate': 5e-5,\n",
    "        'epochs': 3,\n",
    "        'warmup_ratio': 0.1,\n",
    "        'weight_decay': 0.01,\n",
    "        'gradient_accumulation_steps': 2\n",
    "    },\n",
    "    'evaluation': {\n",
    "        'eval_steps': 100,\n",
    "        'save_steps': 500,\n",
    "        'logging_steps': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "# Simple logging setup\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Save config\n",
    "config_path = PATHS['project_root'] / 'configs' / 'training_config.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(CONFIG, f, default_flow_style=False)\n",
    "\n",
    "logger.info(f\"‚úÖ Configuration loaded and saved to {config_path}\")\n",
    "print(f\"üîß Training Config: {CONFIG['model']['name']} on {device}\")\n",
    "print(f\"üìä Batch size: {CONFIG['training']['batch_size']}, Epochs: {CONFIG['training']['epochs']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
