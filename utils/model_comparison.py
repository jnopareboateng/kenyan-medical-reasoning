"""
Model Comparison and Selection Guide
Quick comparison of available LLM implementations for clinical reasoning
"""

import pandas as pd
from utils.logger import CompetitionLogger

logger = CompetitionLogger("ModelComparison")

def compare_models():
    """Compare available LLM models for clinical reasoning"""
    
    models_data = {
        'Model': [
            'FLAN-T5-small (Current)',
            'Phi-4-mini-instruct',
            'Meditron-7B', 
            'Llama-3.2-3B-Instruct'
        ],
        'Parameters': [
            '77M',
            '3.8B (‚Üí1B quantized)',
            '7B (‚Üí1.8B quantized)',
            '3B (‚Üí800M quantized)'
        ],
        'Context Length': [
            '512 tokens',
            '128K tokens',
            '2K tokens',
            '8K tokens'
        ],
        'License': [
            'Apache 2.0',
            'MIT',
            'Llama 2 Community',
            'Llama 3 Community'
        ],
        'Release Date': [
            '2022',
            'Feb 2025',
            'Nov 2023',
            'Sep 2024'
        ],
        'Specialization': [
            'General',
            'Reasoning + Instruction',
            'Medical Domain',
            'General + Instruction'
        ],
        'Competition Fit': [
            '‚ùå Outdated',
            'üöÄ Excellent',
            'üè• Medical Expert',
            '‚ö° Balanced'
        ]
    }
    
    df = pd.DataFrame(models_data)
    
    print("üîç MODEL COMPARISON FOR KENYA CLINICAL REASONING CHALLENGE")
    print("=" * 80)
    print(df.to_string(index=False))
    print("=" * 80)
    
    print("\nüìä RECOMMENDATIONS:")
    print("ü•á PRIMARY: Phi-4-mini-instruct")
    print("   - Latest 2025 model with exceptional reasoning")
    print("   - MIT license (competition compatible)")
    print("   - 128K context for complex clinical cases")
    print("   - Quantizes to under 1B parameters")
    
    print("\nü•à MEDICAL SPECIALIST: Meditron-7B")
    print("   - Purpose-built for medical applications")
    print("   - Trained on PubMed + clinical guidelines") 
    print("   - Strong medical terminology understanding")
    print("   - May require Llama license consideration")
    
    print("\nü•â BALANCED: Llama-3.2-3B-Instruct")
    print("   - Solid instruction following")
    print("   - Good general reasoning capability")
    print("   - Meta's latest small model architecture")
    print("   - Reliable performance across tasks")
    
    print("\n‚ùå AVOID: FLAN-T5-small")
    print("   - 3-year-old architecture")
    print("   - Severely limited reasoning capability")
    print("   - Competitors are using 2024-2025 models")
    print("   - You'll lose with this choice")
    
    logger.info("Model comparison completed")
    return df

def installation_guide():
    """Print installation instructions"""
    
    print("\nüõ†Ô∏è INSTALLATION GUIDE")
    print("=" * 50)
    
    print("\n1Ô∏è‚É£ Install Unsloth (choose your CUDA version):")
    print('pip install "unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git"')
    print("   # For CUDA 12.1 + PyTorch 2.4.0")
    print("   # Adjust cu121-torch240 for your setup")
    
    print("\n2Ô∏è‚É£ Install additional dependencies:")
    print("pip install trl datasets xformers bitsandbytes")
    
    print("\n3Ô∏è‚É£ Test installation:")
    print("python -c 'from unsloth import FastLanguageModel; print(\"‚úÖ Unsloth ready!\")'")
    
    print("\n4Ô∏è‚É£ Update your notebook:")
    print("- Replace 'model = ClinicalT5Model()' with your chosen model")
    print("- Example: 'model = ClinicalPhi4Model()'")
    
    print("\n‚ö†Ô∏è GPU Requirements:")
    print("- Minimum: 8GB VRAM (RTX 3070, Tesla T4)")
    print("- Recommended: 16GB+ VRAM (RTX 4080, A100)")
    print("- All models use 4-bit quantization for efficiency")

if __name__ == "__main__":
    compare_models()
    installation_guide()
